# รายงานการวิเคราะห์ข้อมูลเว็บไซต์มหาวิทยาลัยสวนดุสิต (Data Audit Report)

**URL**: [https://www.dusit.ac.th/home/](https://www.dusit.ac.th/home/)
**วันที่วิเคราะห์**: 13 กุมภาพันธ์ 2026
**สถานะ**: เบื้องต้น (Initial Scan)

## 1. ภาพรวม (Overview)
เว็บไซต์นี้เป็นแหล่งข้อมูลหลักของมหาวิทยาลัยสวนดุสิต (SDU) ทำหน้าที่เป็น Portal กลางที่เชื่อมโยงไปยังหน่วยงานและบริการต่างๆ ข้อมูลส่วนใหญ่เป็นภาษาไทย และมีโครงสร้างที่แบ่งตามกลุ่มผู้ใช้งาน (User-based navigation)

## 2. โครงสร้างข้อมูล (Data Structure)

จากการสำรวจหน้าแรก พบกลุ่มข้อมูลสำคัญดังนี้:

### 2.1 ข้อมูลองค์กร (University Profile)
กลุ่มนี้เป็นข้อมูลเชิง Static ที่เหมาะสำหรับนำไปทำ Knowledge Base พื้นฐานของ AI Agent:
- **ประวัติและพัฒนาการ**: มีไฟล์ PDF [สวนดุสิต จากอดีตถึงปัจจุบัน](https://www.dusit.ac.th/home/wp-content/uploads/2020/09/history_suandusit.pdf) (ต้องใช้เทคนิค Structure Extraction แกะข้อมูล)
- **โครงสร้างการบริหาร**: โครงสร้างมหาวิทยาลัย, สภามหาวิทยาลัย, คณะผู้บริหาร
- **อัตลักษณ์**: สีประจำมหาวิทยาลัย, เพลงมาร์ช, วิสัยทัศน์ (SDU Goal 2568-2571)
- **กฎระเบียบ**: พรบ. มหาวิทยาลัย, การจัดตั้งส่วนงาน

### 2.2 ศูนย์การศึกษา (Campuses & Education Centers)
ข้อมูลกระจายตัวตามวิทยาเขตต่างๆ ซึ่ง AI ต้องสามารถแยกแยะบริบทได้เมื่อผู้ใช้ถาม (เช่น "หอพักที่ศูนย์ฯ ลำปาง"):
- **วิทยาเขตสุพรรณบุรี**
- **ศูนย์การศึกษาลำปาง**
- **ศูนย์การศึกษานครนายก**
- **ศูนย์การศึกษาหัวหิน**
- **ศูนย์การศึกษาตรัง**

### 2.3 บริการและกลุ่มเป้าหมาย (Services & Target Audiences)
มีการแยกทางเข้าสำหรับผู้ใช้แต่ละกลุ่มชัดเจน:
- **ผู้สนใจเข้าศึกษา**: ลิงก์ไปยังระบบรับสมัคร (entrance.dusit.ac.th)
- **นักศึกษาปัจจุบัน**: ระบบบริการนักศึกษา
- **บุคลากร**: ข้อมูลสำหรับเจ้าหน้าที่/อาจารย์
- **ศิษย์เก่า**
- **แหล่งเรียนรู้ออนไลน์ & งานวิจัย**: e-Research, e-Journal

## 3. การประเมินสำหรับการพัฒนา AI Agent (Data Readiness)

### ข้อดี (Pros)
- **การจัดหมวดหมู่ชัดเจน**: ง่ายต่อการทำ Crawler แยกตามหัวข้อ
- **Link Rich**: มี Link เชื่อมโยงไปยังหน่วยงานย่อยจำนวนมาก ช่วยให้ขยายขอบเขตข้อมูลได้ง่าย

### ข้อจำกัด/ความท้าทาย (Challenges)
- **Unstructured Data (PDF)**: ข้อมูลสำคัญหลายส่วน (เช่น ประวัติ, กฎระเบียบ) อยู่ในรูปแบบ PDF ซึ่งต้องใช้โมเดล OCR หรือ PDF Parsing ที่แม่นยำภาษาไทย
- **External Links**: หลายลิงก์จะพาไปยัง Sub-domain (เช่น `entrance.dusit.ac.th`) ซึ่งอาจมีโครงสร้างหน้าเว็บที่แตกต่างกัน ทำให้ต้องเขียน Scraper หลายรูปแบบ

## 4. ข้อเสนอแนะสำหรับการทำ R&D (Recommendations)
1.  **PDF/Table Extraction**: พัฒนาโมเดลเพื่อดึงข้อมูลจาก PDF ประวัติและโครงสร้างองค์กร ให้อยู่ในรูป Markdown
2.  **Specific Crawlers**: สร้าง Crawler แยกสำหรับแต่ละศูนย์การศึกษา เพื่อให้ได้ข้อมูลท้องถิ่นที่ถูกต้อง
3.  **FAQ Generation**: นำข้อมูลจากส่วน "นักศึกษาปัจจุบัน" และ "ผู้สนใจเข้าศึกษา" มาสร้างเป็นคู่มือถาม-ตอบ อัตโนมัติ

---
**Next Step**: ดำเนินการเจาะลึกข้อมูลในส่วน "คณะและหลักสูตร" เพื่อเตรียมข้อมูลสำหรับการตอบคำถามเรื่องการเรียนการสอน
